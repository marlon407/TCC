% ----------------------------------------------------------
% Introdução (exemplo de capítulo sem numeração, mas presente no Sumário)
% ----------------------------------------------------------
\chapter[Introdução]{Introdução}
%\addcontentsline{toc}{chapter}{Introdução}
% ----------------------------------------------------------

Em um mundo cada vez mais interconectado, usuários constantemente exigem maior disponibilidade de informações através da Web. Essas informações não devem apenas estar acessíveis, como também é crucial que seja rápido o tempo para acessá-las. Com a expansão da Internet para dispositivos dos mais diversos tipos, tais como \textit{smartphones}, \textit{tablets} e dispositivos de IoT, questões como tempo de carregamento e consumo de banda vem se tornando fatores cada mais mais debatidos.

O uso de dispositivos móveis para acessar a Internet cresceu 63\% somente em 2016, como aponta o relatório de Previsão Global de Tráfego de Dados Móveis, elaborado pela Cisco. O tráfego de dados móveis passou de  4,4 exabytes \footnote{Um exabyte é equivalente a um bilhão de gigabytes e mil petabytes.} por mês em 2015, para uma média mensal de 7,2 exabytes em 2016. Esse aumento foi resultado de uma adição de cerca de 429 milhões de novos dispositivos móveis à rede, sendo os \textit{smartphones} responsáveis pela maior parte deste crescimento \cite{cisco-network-report}.

Conforme \citeonline{load-time-effects}, usuários tendem a dar mais importância à velocidade em que recebem a informação do que a estética que ela é apresentada. O tempo de carregamento é um fator decisivo para a permanência em uma página Web, uma vez que a maioria dos usuários estão dispostos a aguardar de 6 a 10 segundos antes de abandonar qualquer página. Cada segundo de atraso pode resultar em uma redução de até 7\% nas taxas de conversão, o que para um \textit{e-commerce} que fatura mensalmente R\$ 100.000,00 por exemplo, pode potencialmente custar R\$ 84.000,00 em vendas não efetuadas em um ano.

Para atender estas novas demandas, nos últimos anos houve uma mudança para um modelo de computação chamado cliente/servidor, que aborda as falhas da computação centralizada. Claramente, o modelo de computação centralizado permanece válido em certos ambientes de negócios, no entanto, apesar de muitos benefícios, a computação centralizada é reconhecida como tendo promovido uma cultura de gerenciamento de informações que não conseguiu atender as necessidades de seus clientes.

Em 2010, ocorreu um grande avanço no número de APIs públicas impulsionado pela transição no modelo de comunicação entre aplicações distribuídas, em que estas passaram a utilizar amplamente o protocolo HTTP e o modelo cliente/servidor para a troca de informações através da Web \cite{tcc-ufsc}. A adoção do REST (REpresentational State Transfer) como o método predominante para construir APIs públicas tem ofuscado qualquer outra tecnologia ou abordagem nos últimos anos. Embora várias alternativas (principalmente SOAP) ainda estejam presentes no mercado, adeptos do modelo SOA para construção de aplicações tomaram uma posição definitiva contra eles e optaram por REST como modelo de comunicação e JSON como seu formato de mensagem \cite{programmableweb-rest-losing}.

Segundo \citeonline{rest-webservice}, REST é cada vez mais usado como alternativa ao “já antigo” SOAP em que a principal crítica é a burocracia, algo que o REST possui em uma escala muito menor. REST é baseado no \textit{design} do protocolo HTTP, que já possui diversos mecanismos embutidos para representar recursos como código de \textit{status}, representação de tipos de conteúdo, cabeçalhos, etc. O principal nesta arquitetura são as URLs do sistema e os \textit{resources} \footnote{resource é um recurso, entidade}, aproveitando os métodos HTTP para se comunicar.

Entretanto, com o aumento do uso do REST como modelo de comunicação das APIs, algumas limitações foram expostas, prejudicando o desempenho destas APIs em aspectos cruciais. Clientes com rotinas complexas necessitam realizar consultas complexas, buscando objetos aninhados com diversos relacionamentos. Como uma API REST expõe exclusivamente recursos, é necessário executar diversas buscas no servidor para que algumas rotinas possam ser processadas pelo cliente, uma vez que nem todas as informações necessárias estão presentes na resposta de uma única consulta.

Além disso, em tais cenários são necessárias diversas chamadas na API, pois uma só consulta pode não conter toda informação necessária. Ainda, grande parte destas chamadas irão retornar dados desnecessários ao contexto da rotina que a executou. Esta prática é conhecida como \textit{over-fetching} e ocorre pois é responsabilidade do servidor da API montar o conteúdo da resposta, resultando no tráfego de dados desnecessários.

Foram propostas múltiplas soluções para aumentar a eficiência na busca de dados, algumas em relação aos formatos de consulta e resposta das requisições, enquanto outras estão otimizando o número de solicitações na rede. Uma tendência recente envolve um modelo de consultas declarativas de dados, em que as aplicações clientes especificam quais dados precisam, em vez de buscar tudo a partir de um local específico definido por um URL. Desta forma, estes modelos otimizaram a comunicação com os servidores para obter os dados de forma eficiente: esta é a proposta do GraphQL.

Construído pelos desenvolvedores do Facebook para atender as necessidades internas da rede social em 2012, o GraphQL foi lançado ao público em geral em 2015, e já vem ganhando diversos adeptos. Com a promessa de mitigar alguns problemas crônicos do \textit{design} do REST, como versionamento de APIs, múltiplas viagens de ida e volta e excesso de dados trafegados na rede, a abordagem do Facebook já vem sendo usada por diversas empresas.

REST é de fato, o modelo mais utilizado para comunicação entre cliente e servidor nas aplicações atuais. Este trabalho foca em identificar as diferenças em termos de tempo de carregamento, quantidade de dados trafegados e consumo de recursos entre aplicações REST e o ainda pouco conhecido GraphQL. Para isso, serão criados dois protótipos de API, um implementando o \textit{design} do REST e outro utilizando GraphQL como mecanismo para responder às consultas. O desempenho das duas APIs será então medido, com base em métricas quantitativas e será apresentado a análise dos resultados obtidos.

O restante deste trabalho está organizado da seguinte forma: o capítulo 2 apresenta a evolução das arquiteturas para construção de aplicações; o capítulo 3 aborda os modelos de comunicação entre aplicações, com informações sobre a evolução destes modelos e conceitos em geral, com ênfase nas duas tecnologias analisadas; o capítulo 4 apresenta o ambiente utilizado, as hipóteses levantadas, e detalhes das ferramentas e métricas utilizadas para a análise dos resultados; o capítulo 4 se resume na apresentação e análise dos resultados obtidos. Por fim, e não menos importante, será apresentada a conclusão.